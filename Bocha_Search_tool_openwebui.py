"""
title: ğŸ” Bochaç»¼åˆæœç´¢å·¥å…·é›† - ä¸­æ–‡ç½‘é¡µæœç´¢ã€è‹±æ–‡ç½‘é¡µæœç´¢ã€AIæ™ºèƒ½æœç´¢
author: JiangNanGenius
Github: https://github.com/JiangNanGenius
version: 2.1.1
license: MIT
"""

import os
import requests
import json
from pydantic import BaseModel, Field
import asyncio
from typing import Callable, Any
from urllib.parse import urlparse
import unicodedata
import re
from bs4 import BeautifulSoup


class EventEmitter:
    def __init__(self, event_emitter: Callable[[dict], Any] = None):
        self.event_emitter = event_emitter

    async def emit(self, description="Unknown State", status="in_progress", done=False):
        if self.event_emitter:
            await self.event_emitter(
                {
                    "type": "status",
                    "data": {
                        "status": status,
                        "description": description,
                        "done": done,
                    },
                }
            )


class Tools:
    class Valves(BaseModel):
        BOCHA_API_KEY: str = Field(
            default="YOUR_BOCHA_API_KEY",
            description="ğŸ”‘ Bocha AI APIå¯†é’¥ (ç”¨äºä¸­æ–‡æœç´¢å’ŒAIæœç´¢)",
        )
        LANGSEARCH_API_KEY: str = Field(
            default="YOUR_LANGSEARCH_API_KEY",
            description="ğŸ—ï¸ LangSearch APIå¯†é’¥ (ç”¨äºè‹±æ–‡æœç´¢)",
        )
        CHINESE_WEB_SEARCH_ENDPOINT: str = Field(
            default="https://api.bochaai.com/v1/web-search",
            description="ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç½‘é¡µæœç´¢APIç«¯ç‚¹",
        )
        ENGLISH_WEB_SEARCH_ENDPOINT: str = Field(
            default="https://api.langsearch.com/v1/web-search",
            description="ğŸŒ è‹±æ–‡ç½‘é¡µæœç´¢APIç«¯ç‚¹ï¼ˆLangSearchï¼‰",
        )
        AI_SEARCH_ENDPOINT: str = Field(
            default="https://api.bochaai.com/v1/ai-search",
            description="ğŸ¤– AIæ™ºèƒ½æœç´¢APIç«¯ç‚¹",
        )
        CHINESE_SEARCH_COUNT: int = Field(
            default=10,
            description="ğŸ‡¨ğŸ‡³ ä¸­æ–‡æœç´¢ç»“æœæ•°é‡ (1-10)",
        )
        ENGLISH_SEARCH_COUNT: int = Field(
            default=10,
            description="ğŸŒ è‹±æ–‡æœç´¢ç»“æœæ•°é‡ (1-10)",
        )
        AI_SEARCH_COUNT: int = Field(
            default=10,
            description="ğŸ¤– AIæœç´¢ç»“æœæ•°é‡ (1-50)",
        )
        CITATION_LINKS: bool = Field(
            default=True,
            description="ğŸ”— æ˜¯å¦å‘é€å¼•ç”¨é“¾æ¥å’Œå…ƒæ•°æ®",
        )
        FRESHNESS: str = Field(
            default="noLimit",
            description="â° æœç´¢æ—¶é—´èŒƒå›´ (noLimit, oneDay, oneWeek, oneMonth, oneYear)",
        )

    def __init__(self):
        self.valves = self.Valves()

    async def search_chinese_web(
        self,
        query: str,
        __event_emitter__: Callable[[dict], Any] = None,
    ) -> str:
        """
        ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç½‘é¡µæœç´¢å·¥å…·
        ä¸“é—¨ç”¨äºæœç´¢ä¸­æ–‡ç½‘é¡µå†…å®¹ï¼Œä½¿ç”¨Bochaä¸­æ–‡æœç´¢ç«¯ç‚¹ï¼Œæä¾›å‡†ç¡®çš„ä¸­æ–‡æœç´¢ç»“æœå’Œæ‘˜è¦
        :param query: ä¸­æ–‡æœç´¢å…³é”®è¯
        :return: è¿”å›ä¸­æ–‡ç½‘é¡µæœç´¢ç»“æœ
        """
        emitter = EventEmitter(__event_emitter__)
        await emitter.emit(f"ğŸ” æ­£åœ¨è¿›è¡Œä¸­æ–‡ç½‘é¡µæœç´¢: {query}")

        headers = {
            "Authorization": f"Bearer {self.valves.BOCHA_API_KEY}",
            "Content-Type": "application/json",
        }

        payload = {
            "query": query,
            "freshness": self.valves.FRESHNESS,
            "summary": True,  # æ˜¾ç¤ºæ‘˜è¦
            "count": self.valves.CHINESE_SEARCH_COUNT,
        }

        try:
            await emitter.emit("â³ æ­£åœ¨è¿æ¥ä¸­æ–‡æœç´¢æœåŠ¡å™¨...")
            resp = requests.post(
                self.valves.CHINESE_WEB_SEARCH_ENDPOINT,
                headers=headers,
                json=payload,
                timeout=120,
            )
            resp.raise_for_status()
            data = resp.json()

            source_context_list = []
            counter = 1

            if "data" in data and "webPages" in data["data"]:
                web_pages = data["data"]["webPages"]
                if "value" in web_pages and isinstance(web_pages["value"], list):
                    await emitter.emit(
                        f"ğŸ“„ æ­£åœ¨å¤„ç† {len(web_pages['value'])} ä¸ªä¸­æ–‡ç½‘é¡µç»“æœ..."
                    )
                    for item in web_pages["value"]:
                        url = item.get("url", "")
                        snippet = item.get("snippet", "")
                        summary = item.get("summary", "")
                        name = item.get("name", "")
                        site_name = item.get("siteName", "")
                        date_published = item.get("datePublished", "")

                        source_context_list.append(
                            {
                                "content": summary or snippet,
                                "title": f"ğŸ“„ {name}",
                                "url": url,
                                "site_name": f"ğŸŒ {site_name}" if site_name else "",
                                "date_published": (
                                    f"ğŸ“… {date_published}" if date_published else ""
                                ),
                                "source_type": "ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç½‘é¡µ",
                            }
                        )

                        if __event_emitter__ and self.valves.CITATION_LINKS:
                            await __event_emitter__(
                                {
                                    "type": "citation",
                                    "data": {
                                        "document": [summary or snippet],
                                        "metadata": [
                                            {
                                                "source": url,
                                                "title": f"ğŸ“„ {name}",
                                            }
                                        ],
                                        "source": {
                                            "name": f"ğŸ‡¨ğŸ‡³ {name}",
                                            "url": url,
                                            "type": "webpage",
                                        },
                                    },
                                }
                            )
                        counter += 1

            await emitter.emit(
                status="complete",
                description=f"âœ… ä¸­æ–‡ç½‘é¡µæœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(source_context_list)} ä¸ªç»“æœ",
                done=True,
            )
            return json.dumps(source_context_list, ensure_ascii=False)

        except requests.exceptions.RequestException as e:
            error_details = {
                "error": str(e),
                "type": "âŒ ä¸­æ–‡ç½‘é¡µæœç´¢é”™è¯¯",
                "endpoint": self.valves.CHINESE_WEB_SEARCH_ENDPOINT,
                "api_key_used": "BOCHA_API_KEY",
                "payload": payload,
            }
            await emitter.emit(
                status="error",
                description=f"âŒ ä¸­æ–‡ç½‘é¡µæœç´¢å‡ºé”™: {str(e)}",
                done=True,
            )
            return json.dumps(error_details, ensure_ascii=False)

    async def search_english_web(
        self,
        query: str,
        __event_emitter__: Callable[[dict], Any] = None,
    ) -> str:
        """
        ğŸŒ è‹±æ–‡ç½‘é¡µæœç´¢å·¥å…·
        ä¸“é—¨ç”¨äºæœç´¢è‹±æ–‡ç½‘é¡µå†…å®¹ï¼Œä½¿ç”¨LangSearchè‹±æ–‡æœç´¢ç«¯ç‚¹ï¼Œæä¾›å‡†ç¡®çš„è‹±æ–‡æœç´¢ç»“æœå’Œæ‘˜è¦
        :param query: è‹±æ–‡æœç´¢å…³é”®è¯
        :return: è¿”å›è‹±æ–‡ç½‘é¡µæœç´¢ç»“æœ
        """
        emitter = EventEmitter(__event_emitter__)
        await emitter.emit(f"ğŸ” æ­£åœ¨è¿›è¡Œè‹±æ–‡ç½‘é¡µæœç´¢: {query}")

        headers = {
            "Authorization": f"Bearer {self.valves.LANGSEARCH_API_KEY}",
            "Content-Type": "application/json",
        }

        payload = {
            "query": query,
            "freshness": self.valves.FRESHNESS,
            "summary": True,  # æ˜¾ç¤ºæ‘˜è¦
            "count": self.valves.ENGLISH_SEARCH_COUNT,
        }

        try:
            await emitter.emit("â³ æ­£åœ¨è¿æ¥è‹±æ–‡æœç´¢æœåŠ¡å™¨...")
            resp = requests.post(
                self.valves.ENGLISH_WEB_SEARCH_ENDPOINT,
                headers=headers,
                json=payload,
                timeout=120,
            )
            resp.raise_for_status()
            data = resp.json()

            source_context_list = []
            counter = 1

            if "data" in data and "webPages" in data["data"]:
                web_pages = data["data"]["webPages"]
                if "value" in web_pages and isinstance(web_pages["value"], list):
                    await emitter.emit(
                        f"ğŸ“„ æ­£åœ¨å¤„ç† {len(web_pages['value'])} ä¸ªè‹±æ–‡ç½‘é¡µç»“æœ..."
                    )
                    for item in web_pages["value"]:
                        url = item.get("url", "")
                        snippet = item.get("snippet", "")
                        summary = item.get("summary", "")
                        name = item.get("name", "")
                        site_name = item.get("siteName", "")
                        date_published = item.get("datePublished", "")

                        source_context_list.append(
                            {
                                "content": summary or snippet,
                                "title": f"ğŸ“„ {name}",
                                "url": url,
                                "site_name": f"ğŸŒ {site_name}" if site_name else "",
                                "date_published": (
                                    f"ğŸ“… {date_published}" if date_published else ""
                                ),
                                "source_type": "ğŸŒ è‹±æ–‡ç½‘é¡µ",
                            }
                        )

                        if __event_emitter__ and self.valves.CITATION_LINKS:
                            await __event_emitter__(
                                {
                                    "type": "citation",
                                    "data": {
                                        "document": [summary or snippet],
                                        "metadata": [
                                            {
                                                "source": url,
                                                "title": f"ğŸ“„ {name}",
                                            }
                                        ],
                                        "source": {
                                            "name": f"ğŸŒ {name}",
                                            "url": url,
                                            "type": "webpage",
                                        },
                                    },
                                }
                            )
                        counter += 1

            await emitter.emit(
                status="complete",
                description=f"âœ… è‹±æ–‡ç½‘é¡µæœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(source_context_list)} ä¸ªç»“æœ",
                done=True,
            )
            return json.dumps(source_context_list, ensure_ascii=False)

        except requests.exceptions.RequestException as e:
            error_details = {
                "error": str(e),
                "type": "âŒ è‹±æ–‡ç½‘é¡µæœç´¢é”™è¯¯",
                "endpoint": self.valves.ENGLISH_WEB_SEARCH_ENDPOINT,
                "api_key_used": "LANGSEARCH_API_KEY",
                "payload": payload,
            }
            await emitter.emit(
                status="error",
                description=f"âŒ è‹±æ–‡ç½‘é¡µæœç´¢å‡ºé”™: {str(e)}",
                done=True,
            )
            return json.dumps(error_details, ensure_ascii=False)

    async def search_ai_intelligent(
        self,
        query: str,
        __event_emitter__: Callable[[dict], Any] = None,
    ) -> str:
        """
        ğŸ¤– AIæ™ºèƒ½æœç´¢å·¥å…·
        ä½¿ç”¨AIæŠ€æœ¯æä¾›æ™ºèƒ½æœç´¢ç»“æœï¼ŒåŒ…å«AIç”Ÿæˆçš„ç­”æ¡ˆã€æ€»ç»“å’Œè¿½é—®é—®é¢˜
        æ”¯æŒå¤šæ¨¡æ€æœç´¢ç»“æœï¼ˆç½‘é¡µã€å›¾ç‰‡ã€æ¨¡æ€å¡ç­‰ï¼‰
        :param query: æœç´¢æŸ¥è¯¢å…³é”®è¯
        :return: è¿”å›AIæ™ºèƒ½æœç´¢ç»“æœï¼ŒåŒ…å«AIç”Ÿæˆçš„ç­”æ¡ˆ
        """
        emitter = EventEmitter(__event_emitter__)
        await emitter.emit(f"ğŸ¤– æ­£åœ¨è¿›è¡ŒAIæ™ºèƒ½æœç´¢: {query}")

        headers = {
            "Authorization": f"Bearer {self.valves.BOCHA_API_KEY}",
            "Content-Type": "application/json",
        }

        payload = {
            "query": query,
            "freshness": self.valves.FRESHNESS,
            "answer": True,  # å¯ç”¨AIç”Ÿæˆç­”æ¡ˆ
            "stream": False,  # éæµå¼å“åº”
            "count": self.valves.AI_SEARCH_COUNT,
        }

        try:
            await emitter.emit("â³ æ­£åœ¨è¿æ¥AIæ™ºèƒ½æœç´¢æœåŠ¡å™¨...")
            resp = requests.post(
                self.valves.AI_SEARCH_ENDPOINT,
                headers=headers,
                json=payload,
                timeout=120,
            )
            resp.raise_for_status()
            data = resp.json()

            source_context_list = []
            ai_answers = []
            follow_up_questions = []
            counter = 1

            await emitter.emit("ğŸ§  AIæ­£åœ¨åˆ†ææœç´¢ç»“æœ...")

            if "messages" in data:
                for msg in data["messages"]:
                    msg_role = msg.get("role", "")
                    msg_type = msg.get("type", "")
                    content_type = msg.get("content_type", "")
                    content = msg.get("content", "")

                    # å¤„ç†ç½‘é¡µæœç´¢ç»“æœ
                    if (
                        msg_role == "assistant"
                        and msg_type == "source"
                        and content_type == "webpage"
                    ):
                        try:
                            content_obj = json.loads(content)
                            if "value" in content_obj and isinstance(
                                content_obj["value"], list
                            ):
                                await emitter.emit(
                                    f"ğŸ“„ æ­£åœ¨å¤„ç† {len(content_obj['value'])} ä¸ªAIæœç´¢ç»“æœ..."
                                )
                                for item in content_obj["value"]:
                                    url = item.get("url", "")
                                    snippet = item.get("snippet", "")
                                    summary = item.get("summary", "")
                                    name = item.get("name", "")
                                    site_name = item.get("siteName", "")
                                    date_published = item.get("datePublished", "")

                                    source_context_list.append(
                                        {
                                            "content": summary or snippet,
                                            "title": f"ğŸ“„ {name}",
                                            "url": url,
                                            "site_name": (
                                                f"ğŸŒ {site_name}" if site_name else ""
                                            ),
                                            "date_published": (
                                                f"ğŸ“… {date_published}"
                                                if date_published
                                                else ""
                                            ),
                                            "source_type": "ğŸ¤– AIæ™ºèƒ½æœç´¢",
                                        }
                                    )

                                    if __event_emitter__ and self.valves.CITATION_LINKS:
                                        await __event_emitter__(
                                            {
                                                "type": "citation",
                                                "data": {
                                                    "document": [summary or snippet],
                                                    "metadata": [
                                                        {
                                                            "source": url,
                                                            "title": f"ğŸ“„ {name}",
                                                        }
                                                    ],
                                                    "source": {
                                                        "name": f"ğŸ¤– {name}",
                                                        "url": url,
                                                        "type": "webpage",
                                                    },
                                                },
                                            }
                                        )
                                    counter += 1
                        except json.JSONDecodeError:
                            pass

                    # å¤„ç†AIç”Ÿæˆçš„ç­”æ¡ˆ
                    elif (
                        msg_role == "assistant"
                        and msg_type == "answer"
                        and content_type == "text"
                    ):
                        ai_answers.append(f"ğŸ¤– {content}")
                        await emitter.emit(f"âœ¨ AIç”Ÿæˆäº†ç¬¬ {len(ai_answers)} ä¸ªå›ç­”...")

                    # å¤„ç†è¿½é—®é—®é¢˜
                    elif (
                        msg_role == "assistant"
                        and msg_type == "follow_up"
                        and content_type == "text"
                    ):
                        follow_up_questions.append(f"ğŸ’­ {content}")
                        await emitter.emit(
                            f"ğŸ’¡ AIå»ºè®®äº†ç¬¬ {len(follow_up_questions)} ä¸ªè¿½é—®é—®é¢˜..."
                        )

            # ç»„åˆç»“æœ
            result = {
                "search_results": source_context_list,
                "ai_answers": ai_answers,
                "follow_up_questions": follow_up_questions,
                "summary": {
                    "total_results": len(source_context_list),
                    "ai_answers_count": len(ai_answers),
                    "follow_up_count": len(follow_up_questions),
                    "search_type": "ğŸ¤– AIæ™ºèƒ½æœç´¢",
                },
            }

            await emitter.emit(
                status="complete",
                description=f"ğŸ‰ AIæ™ºèƒ½æœç´¢å®Œæˆï¼æ‰¾åˆ° {len(source_context_list)} ä¸ªç»“æœï¼Œç”Ÿæˆ {len(ai_answers)} ä¸ªAIç­”æ¡ˆï¼Œ{len(follow_up_questions)} ä¸ªè¿½é—®å»ºè®®",
                done=True,
            )
            return json.dumps(result, ensure_ascii=False)

        except requests.exceptions.RequestException as e:
            error_details = {
                "error": str(e),
                "type": "âŒ AIæ™ºèƒ½æœç´¢é”™è¯¯",
                "endpoint": self.valves.AI_SEARCH_ENDPOINT,
                "api_key_used": "BOCHA_API_KEY",
                "payload": payload,
            }
            await emitter.emit(
                status="error",
                description=f"âŒ AIæ™ºèƒ½æœç´¢å‡ºé”™: {str(e)}",
                done=True,
            )
            return json.dumps(error_details, ensure_ascii=False)
